# attribute.py
# Lighting Spec Finder v4.2 â€” GPT-4o è‡ªå‹•æŠ½å– + JSON å¿«å–ï¼ˆè¼‰å…¥/å„²å­˜ï¼‰+ å±¬æ€§ç¯©é¸

import os, io, re, json, time, base64
import gradio as gr
import fitz                          # PyMuPDFï¼šè®€ PDF
from PIL import Image                # åœ–ç‰‡è™•ç†
from dotenv import load_dotenv
from openai import OpenAI

# ===== åŸºæœ¬è¨­å®š =====
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âš ï¸ æ‰¾ä¸åˆ° OPENAI_API_KEYï¼Œè«‹åœ¨ .env ä¸­è¨­å®šã€‚")
client = OpenAI(api_key=OPENAI_API_KEY)

# å…¨åŸŸè³‡æ–™
products = []                          # è§£ææˆ–è¼‰å…¥å¾Œçš„æ‰€æœ‰ç”¢å“
DEFAULT_JSON = "merged_products.json"  # è§£æå®Œæˆè‡ªå‹•è¼¸å‡ºçš„æª”å


# =========================
# å…±ç”¨å·¥å…·
# =========================
def _find_json(s: str):
    """å¾æ¨¡å‹è¼¸å‡ºè£¡ï¼Œç›¡åŠ›æŠ“å‡º JSON é™£åˆ—æˆ–ç‰©ä»¶å† loadsã€‚æŠ“ä¸åˆ°å°±å› Noneã€‚"""
    if not s:
        return None
    m = re.search(r"\[\s*\{.*\}\s*\]", s, flags=re.S)  # å…ˆæ‰¾é™£åˆ—
    if not m:
        m = re.search(r"\{\s*\".*\}\s*", s, flags=re.S) # å†æ‰¾ç‰©ä»¶
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except:
        return None

def _jpeg_data_url_from_page(page: fitz.Page, max_w=1280, quality=80) -> str:
    """æŠŠ PDF é é¢è½‰æˆ JPEG Data URLï¼Œæä¾›çµ¦ VLM"""
    pix = page.get_pixmap(matrix=fitz.Matrix(1.5, 1.5))
    img = Image.open(io.BytesIO(pix.tobytes("png"))).convert("RGB")
    if img.width > max_w:
        h = int(img.height * (max_w / img.width))
        img = img.resize((max_w, h), Image.LANCZOS)
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=quality, optimize=True)
    b64 = base64.b64encode(buf.getvalue()).decode("ascii")
    return f"data:image/jpeg;base64,{b64}"

def _to_number(x):
    """å­—ä¸²æ•¸å­— â†’ floatï¼ˆå»é€—è™Ÿã€æŠ“ç¬¬ä¸€å€‹æ•¸å­—ç‰‡æ®µï¼‰"""
    try:
        s = str(x).replace(",", "")
        m = re.search(r"[-+]?\d+(\.\d+)?", s)
        return float(m.group(0)) if m else 0.0
    except Exception:
        return 0.0


# =========================
# GPT-4o ä¸€èˆ¬è¦æ ¼æŠ½å–ï¼ˆä¸€é ï¼‰
# =========================
def _gpt_json_from_text(text: str, page_no: int, retries=2):
    """
    åªç”¨æ–‡å­—è¨Šæ¯è«‹ gpt-4o ç”¢ç”Ÿ JSONã€‚
    ç”¨ response_format å¼·åˆ¶å› JSONï¼›ä»å‚™æ´ç”¨ _find_json è§£æã€‚
    """
    system = (
        "ä½ æ˜¯ç‡ˆå…·è¦æ ¼æŠ½å–åŠ©æ‰‹ã€‚"
        "åªè¼¸å‡º JSONï¼Œä¸è¦ä»»ä½•è§£é‡‹ã€‚"
        "å¦‚æœæ²’æœ‰ç”¢å“ï¼Œè«‹è¼¸å‡ºç©ºé™£åˆ— []ã€‚"
    )
    user = (
        f"è«‹å¾ä»¥ä¸‹æ–‡å­—ä¸­æŠ½å–ç”¢å“è¦æ ¼ï¼Œè¼¸å‡º JSON é™£åˆ—ï¼š\n"
        f"[{{\"model\":\"...\",\"watt\":æ•¸å­—,\"cct\":æ•¸å­—,\"beam\":æ•¸å­—,"
        f"\"lumen\":æ•¸å­—,\"cri\":æ•¸å­—æˆ–å­—ä¸²,\"ip\":\"...\",\"voltage\":\"...\",\"price\":æ•¸å­—æˆ–å­—ä¸²}}]\n\n"
        f"ç¬¬ {page_no} é å…§å®¹ï¼š\n{text[:8000]}"  # é¿å…è¶…é•·
    )
    for _ in range(retries+1):
        try:
            resp = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role":"system","content":system},{"role":"user","content":user}],
                temperature=0.2,
                response_format={"type": "json_object"},  # ç›¡é‡è®“å®ƒåªå› JSON
                max_tokens=1200,
            )
            out = resp.choices[0].message.content or ""
            js = _find_json(out)
            if js is None:
                try:
                    js = json.loads(out)  # æœ‰äº›æƒ…æ³ç›´æ¥æ˜¯åˆæ³• JSON
                except:
                    js = None
            if js is None:
                continue
            if isinstance(js, dict):
                if "items" in js and isinstance(js["items"], list):
                    return js["items"]
                else:
                    return [js]
            if isinstance(js, list):
                return js
        except Exception:
            time.sleep(1.2)
    return None

def _gpt_json_from_image(page: fitz.Page, page_no: int, retries=2):
    """
    ç”¨åœ–ç‰‡ï¼ˆVLMï¼‰è«‹ gpt-4o ç”¢ç”Ÿ JSONã€‚ä½œç‚ºç„¡æ–‡å­—æˆ–ç´”è¡¨æ ¼é çš„å‚™æ´ã€‚
    """
    system = (
        "ä½ æ˜¯ç‡ˆå…·è¦æ ¼æŠ½å–åŠ©æ‰‹ã€‚"
        "åªè¼¸å‡º JSONï¼Œä¸è¦ä»»ä½•è§£é‡‹ã€‚"
        "å¦‚æœæ²’æœ‰ç”¢å“ï¼Œè«‹è¼¸å‡ºç©ºé™£åˆ— []ã€‚"
    )
    data_url = _jpeg_data_url_from_page(page)
    user_content = [
        {"type": "text", "text": (
            "å¾åœ–ç‰‡ä¸­è®€å–ç‡ˆå…·è¦æ ¼ï¼Œè¼¸å‡º JSON é™£åˆ—ï¼š"
            "[{\"model\":\"...\",\"watt\":æ•¸å­—,\"cct\":æ•¸å­—,\"beam\":æ•¸å­—,"
            "\"lumen\":æ•¸å­—,\"cri\":æ•¸å­—æˆ–å­—ä¸²,\"ip\":\"...\",\"voltage\":\"...\",\"price\":æ•¸å­—æˆ–å­—ä¸²}]"
        )},
        {"type": "image_url", "image_url": {"url": data_url}},
    ]
    for _ in range(retries+1):
        try:
            resp = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role":"system","content":system},
                    {"role":"user","content":user_content}
                ],
                temperature=0.2,
                max_tokens=1200
            )
            out = resp.choices[0].message.content or ""
            js = _find_json(out)
            if js is None:
                try:
                    js = json.loads(out)
                except:
                    js = None
            if js is None:
                continue
            if isinstance(js, dict):
                return [js]
            if isinstance(js, list):
                return js
        except Exception:
            time.sleep(1.2)
    return None


# =========================
# PDF å…¨æ–‡æŠ½å–ï¼ˆâ†’ productsï¼›åŒæ™‚è¼¸å‡º JSONï¼‰
# =========================
def parse_pdf_with_gpt4o(pdf_input):
    """
    - é€é ï¼šæ–‡å­—â†’JSONï¼›å¤±æ•—â†’åœ–ç‰‡â†’JSON
    - æ¯é å°å‡ºæˆåŠŸ/å¤±æ•—
    - çµæŸå¾ŒæŠŠ products å­˜æˆ merged_products.json
    """
    global products
    products = []

    # gr.File æœƒå‚³å…¥ä¸€å€‹ç‰©ä»¶ï¼Œå– nameï¼›ä¹Ÿæ”¯æ´ç›´æ¥å‚³å­—ä¸²è·¯å¾‘
    pdf_path = pdf_input if isinstance(pdf_input, str) else pdf_input.name

    doc = fitz.open(pdf_path)
    total = len(doc)
    ok, fail = 0, 0

    for i, page in enumerate(doc, start=1):
        text = (page.get_text("text") or "").strip()

        items = None
        if text:  # å…ˆè©¦æ–‡å­—
            items = _gpt_json_from_text(text, i, retries=2)

        if not items:  # æ–‡å­—å¤±æ•— â†’ ç”¨åœ–
            items = _gpt_json_from_image(page, i, retries=2)

        if items:
            # æ­£è¦åŒ–æ¬„ä½å‹æ…‹ï¼Œé¿å…å¾ŒçºŒç¯©é¸æ™‚å‡ºéŒ¯
            normed = []
            for it in items:
                if not isinstance(it, dict):
                    continue
                d = dict(it)
                for k in ["watt","cct","beam","lumen","price","cri"]:
                    if k in d:
                        d[k] = _to_number(d[k])
                normed.append(d)

            products.extend(normed)
            ok += 1
            print(f"âœ… ç¬¬ {i}/{total} é è§£ææˆåŠŸï¼šæ–°å¢ {len(normed)} ç­†ï¼ˆç´¯è¨ˆ {len(products)}ï¼‰")
        else:
            fail += 1
            print(f"âš ï¸ ç¬¬ {i}/{total} é è§£æå¤±æ•—")

    # å­˜ JSON å¿«å–
    try:
        with open(DEFAULT_JSON, "w", encoding="utf-8") as f:
            json.dump(products, f, ensure_ascii=False, indent=2)
        save_msg = f"âœ… å·²è¼¸å‡º {DEFAULT_JSON}ï¼ˆ{len(products)} ç­†ï¼‰"
    except Exception as e:
        save_msg = f"âŒ è¼¸å‡º JSON å¤±æ•—ï¼š{e}"

    return f"å®Œæˆï¼šæˆåŠŸ {ok} é  / å¤±æ•— {fail} é ï¼›å…±è§£æ {len(products)} ç­†ã€‚\n{save_msg}"


# =========================
# æŸ¥è©¢ / ç¯©é¸
# =========================
def ui_search(query: str):
    if not products:
        return "âš ï¸ å°šæœªè¼‰å…¥ä»»ä½•ç”¢å“è³‡æ–™ã€‚è«‹å…ˆè§£æ PDF æˆ–è¼‰å…¥ JSONã€‚"
    if not query or not query.strip():
        return "âš ï¸ è«‹è¼¸å…¥å‹è™Ÿæˆ–é—œéµå­—ã€‚"

    query_type = classify_query_with_llm(query)
    lines = []

    if query_type == "series":
        matched = find_by_series_name(query)
        if not matched:
            return f"âŒ æ‰¾ä¸åˆ°èˆ‡ç³»åˆ—ã€Œ{query}ã€ç›¸é—œçš„ç”¢å“ã€‚"
        lines.append(f"### ğŸ“š ç³»åˆ—æŸ¥è©¢çµæœï¼š{len(matched)} ç­†\n")
        for it in matched[:20]:
            lines.append(
                f"- **{it.get('model','æœªå‘½å')}** | "
                f"{it.get('watt','?')}W | {it.get('cct','?')}K | "
                f"å…‰æŸè§’ {it.get('beam','?')}Â° | å…‰é€šé‡ {it.get('lumen','?')}lm | "
                f"åƒ¹æ ¼ {it.get('price','?')} å…ƒ"
            )
        return "\n".join(lines)

    else:  # é è¨­ç•¶æˆå‹è™ŸæŸ¥è©¢
        q = query.strip().lower()
        matched = []
        for p in products:
            model = str(p.get("model", "")).lower()
            if q in model:
                matched.append(p)

        if not matched:
            return f"âŒ æ‰¾ä¸åˆ°å‹è™Ÿã€Œ{query}ã€ã€‚"

        lines.append(f"### ğŸ” å‹è™ŸæŸ¥è©¢çµæœï¼š{len(matched)} ç­†\n")
        for it in matched[:20]:
            lines.append(
                f"- **{it.get('model','æœªå‘½å')}** | "
                f"{it.get('watt','?')}W | {it.get('cct','?')}K | "
                f"å…‰æŸè§’ {it.get('beam','?')}Â° | å…‰é€šé‡ {it.get('lumen','?')}lm | "
                f"åƒ¹æ ¼ {it.get('price','?')} å…ƒ"
            )
        return "\n".join(lines)


def ui_filter(
    series_name,
    watt_lo, watt_hi,
    cct_lo, cct_hi,
    beam_lo, beam_hi,
    lumen_lo, lumen_hi,
    price_lo, price_hi,
    topk
):
    if not products:
        return "âš ï¸ å°šæœªè¼‰å…¥ä»»ä½•ç”¢å“è³‡æ–™ã€‚è«‹å…ˆè§£æ PDF æˆ–è¼‰å…¥ JSONã€‚"

    # ğŸ” Step 1. å…ˆä¾ç³»åˆ—éæ¿¾ï¼ˆè‹¥æœ‰è¼¸å…¥ï¼‰
    if series_name and series_name.strip():
        q = series_name.strip().lower()
        filtered = [p for p in products if q in str(p.get("model", "")).lower()]
        if not filtered:
            return f"âŒ æ‰¾ä¸åˆ°èˆ‡ç³»åˆ—ã€Œ{series_name}ã€ç›¸é—œçš„ç”¢å“ã€‚"
    else:
        filtered = products[:]  # æ²’æœ‰ç³»åˆ—è¼¸å…¥å°±ç”¨å…¨éƒ¨

    # ğŸ”¢ Step 2. å†ä¾å±¬æ€§ç¯©é¸
    def num(x): 
        try: return float(x)
        except: return 0

    result = []
    for p in filtered:
        w  = num(p.get("watt", 0))
        c  = num(p.get("cct", 0))
        b  = num(p.get("beam", 0))
        l  = num(p.get("lumen", 0))
        pr = num(p.get("price", 0))

        if not (watt_lo <= w  <= watt_hi):  continue
        if not (cct_lo  <= c  <= cct_hi):   continue
        if not (beam_lo <= b  <= beam_hi):  continue
        if not (lumen_lo<= l  <= lumen_hi): continue
        if not (price_lo<= pr <= price_hi): continue
        result.append(p)

    if not result:
        return f"âŒ ç³»åˆ—ã€Œ{series_name or 'å…¨éƒ¨'}ã€ä¸­æ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„ç”¢å“ã€‚"

    # ğŸ§¾ Step 3. æ ¼å¼åŒ–è¼¸å‡º
    lines = [f"### ç¯©é¸çµæœï¼šç³»åˆ— {series_name or 'ï¼ˆå…¨éƒ¨ï¼‰'} å…± {len(result)} ç­†ï¼ˆé¡¯ç¤ºå‰ {int(topk)} ç­†ï¼‰\n"]
    for it in result[:int(topk)]:
        lines.append(
            f"- **{it.get('model','æœªå‘½å')}** | "
            f"{it.get('watt','?')}W | {it.get('cct','?')}K | "
            f"å…‰æŸè§’ {it.get('beam','?')}Â° | å…‰é€šé‡ {it.get('lumen','?')}lm | "
            f"åƒ¹æ ¼ {it.get('price','?')} å…ƒ"
        )
    return "\n".join(lines)

# ==========================================
# ğŸ” æ™ºæ…§ç³»åˆ—/å‹è™Ÿè¾¨è­˜èˆ‡ç¯©é¸è¼”åŠ©æ¨¡çµ„
# ==========================================
def classify_query_with_llm(user_query: str) -> str:
    """
    ä½¿ç”¨ GPT åˆ¤æ–·ä½¿ç”¨è€…è¼¸å…¥å±¬æ–¼ã€Œç³»åˆ—ã€é‚„æ˜¯ã€Œå‹è™Ÿã€ã€‚
    å›å‚³ 'series' æˆ– 'model'
    """
    if not user_query:
        return "unknown"
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role":"system","content":"ä½ æ˜¯ä¸€å€‹ç‡ˆå…·è³‡æ–™åˆ†é¡åŠ©æ‰‹ï¼Œåªå›ç­” 'series' æˆ– 'model'ã€‚"},
                {"role":"user","content":f"åˆ¤æ–·ä»¥ä¸‹è¼¸å…¥å±¬æ–¼ç‡ˆå…·ã€ç³»åˆ—åã€é‚„æ˜¯ã€å‹è™Ÿåã€ï¼š{user_query}"}
            ],
            temperature=0
        )
        ans = resp.choices[0].message.content.strip().lower()
        if "series" in ans:
            return "series"
        if "model" in ans:
            return "model"
    except Exception as e:
        print(f"LLM åˆ¤æ–·å¤±æ•—ï¼š{e}")
    return "unknown"


def find_by_series_name(series_query: str):
    """
    å¾ JSON çš„æ–‡å­—æ¬„ä½ä¸­æ‰¾å‡ºå±¬æ–¼åŒç³»åˆ—çš„ç”¢å“ã€‚
    ä¾‹å¦‚ä½¿ç”¨è€…è¼¸å…¥ 'T5 ç¯€æ¨™' æˆ– 'T5BA1'ï¼Œæˆ–è€…çµå°¾åŒ…å«"ç³»åˆ—"äºŒå­— â†’ æ‰¾å‡ºæ‰€æœ‰åŒ…å«é€™é—œéµè©çš„ modelã€‚
    """
    q = series_query.strip().lower()
    matched = []
    for p in products:
        if q in str(p.get("model", "")).lower():
            matched.append(p)
    return matched


# =========================
# JSON å¿«å–ï¼šè¼‰å…¥
# =========================
def load_products_from_json(path: str = DEFAULT_JSON):
    """å¾ JSON è¼‰å…¥ productsï¼ˆè¦†è“‹å…¨åŸŸï¼‰"""
    global products
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, list):
            products = data
            return f"âœ… å·²è¼‰å…¥ {path}ï¼š{len(products)} ç­†"
        return "âŒ JSON æ ¼å¼ä¸æ˜¯é™£åˆ—ã€‚"
    except Exception as e:
        return f"âŒ è¼‰å…¥ JSON å¤±æ•—ï¼š{e}"

def load_products_from_uploaded_json(file_obj):
    """Gradio ä¸Šå‚³ JSON è¼‰å…¥"""
    if not file_obj:
        return "âš ï¸ è«‹å…ˆä¸Šå‚³ JSON æª”ã€‚"
    return load_products_from_json(file_obj.name)


# =========================
# Gradio UI
# =========================
with gr.Blocks(title="Lighting Spec Finder v4.2 â€” GPT-4o + JSON å¿«å–") as demo:
    gr.Markdown("# ğŸ’¡ Lighting Spec Finder v4.2 â€” è§£æå¾Œå¯å­˜ JSONï¼Œé‡å•Ÿç›´æ¥è¼‰å…¥ä½¿ç”¨")

    # A. å…ˆè¼‰å…¥ JSONï¼ˆé‡å•Ÿå¾Œå»ºè­°ç”¨ï¼‰
    gr.Markdown("## A. è¼‰å…¥ç¾æœ‰ JSONï¼ˆé‡å•Ÿå¾Œå…é‡è·‘ï¼‰")
    with gr.Row():
        btn_load_default = gr.Button("ğŸ“‚ è¼‰å…¥ merged_products.json")
        json_upload = gr.File(label="æˆ–ä¸Šå‚³è‡ªè¨‚ JSONï¼ˆé™£åˆ—æ ¼å¼ï¼‰", file_types=[".json"])
        btn_load_uploaded = gr.Button("ğŸ“¤ è¼‰å…¥ä¸Šå‚³ JSON")
    status_load = gr.Markdown("ï¼ˆå°šæœªè¼‰å…¥ï¼‰")
    btn_load_default.click(lambda: load_products_from_json(DEFAULT_JSON), outputs=[status_load])
    btn_load_uploaded.click(load_products_from_uploaded_json, inputs=[json_upload], outputs=[status_load])

    # B. é‡æ–°è§£æ PDFï¼ˆæœƒè‡ªå‹•å­˜ JSONï¼‰
    gr.Markdown("## B. é‡æ–°è§£æ PDFï¼ˆGPT-4o å…¨æŠ½å–ï¼Œå®Œæˆå¾Œè‡ªå‹•è¼¸å‡º JSONï¼‰")
    with gr.Row():
        pdf_input = gr.File(label="ä¸Šå‚³ catalog PDF", file_types=[".pdf"], scale=3)
        btn_parse = gr.Button("ğŸš€ é–‹å§‹è§£æï¼ˆå…¨æ–‡ï¼‰", scale=1)
    status_parse = gr.Markdown("ï¼ˆæœªé–‹å§‹ï¼‰")
    btn_parse.click(parse_pdf_with_gpt4o, inputs=pdf_input, outputs=status_parse)

    # C. æŸ¥è©¢ / ç¯©é¸
    gr.Markdown("## C. æŸ¥è©¢ / ç¯©é¸")
    with gr.Row():
        query_input = gr.Textbox(label="è¼¸å…¥å‹è™Ÿæˆ–é—œéµå­—ï¼ˆä¾‹å¦‚ï¼šD-FXTR7N æˆ– è»Œé“ç‡ˆï¼‰", placeholder="è«‹å…ˆè¼‰å…¥ JSON æˆ–è§£æ PDF", scale=4)
        btn_search = gr.Button("æŸ¥è©¢", variant="primary", scale=1)
    search_result = gr.Markdown("ï¼ˆå°šæœªæŸ¥è©¢ï¼‰")
    btn_search.click(ui_search, inputs=[query_input], outputs=[search_result])
    
    series_input = gr.Textbox(label="ç³»åˆ—åç¨±ï¼ˆå¯é¸ï¼‰", placeholder="ä¾‹å¦‚ï¼šT5ã€D-T5BA1ã€OD ç³»åˆ—ç­‰ï¼Œå¯ç•™ç©º")

    gr.Markdown("### å±¬æ€§ç¯©é¸ï¼ˆé›™é ­æ»‘æ¡¿ï¼‰")
    with gr.Row():
        watt_lo = gr.Slider(0,200,0,step=1,label="åŠŸç‡æœ€å° W")
        watt_hi = gr.Slider(0,200,200,step=1,label="åŠŸç‡æœ€å¤§ W")
    with gr.Row():
        cct_lo = gr.Slider(2000,7000,2700,step=50,label="è‰²æº«æœ€å° K")
        cct_hi = gr.Slider(2000,7000,6500,step=50,label="è‰²æº«æœ€å¤§ K")
    with gr.Row():
        beam_lo = gr.Slider(0,120,0,step=1,label="å…‰æŸè§’æœ€å° Â°")
        beam_hi = gr.Slider(0,120,120,step=1,label="å…‰æŸè§’æœ€å¤§ Â°")
    with gr.Row():
        lumen_lo = gr.Slider(0,10000,0,step=10,label="å…‰é€šé‡æœ€å° lm")
        lumen_hi = gr.Slider(0,10000,10000,step=10,label="å…‰é€šé‡æœ€å¤§ lm")
    with gr.Row():
        price_lo = gr.Slider(0,100000,0,step=100,label="åƒ¹æ ¼æœ€å°")
        price_hi = gr.Slider(0,100000,100000,step=100,label="åƒ¹æ ¼æœ€å¤§")
    with gr.Row():
        topk = gr.Slider(1,20,10,step=1,label="æœ€å¤šé¡¯ç¤ºç­†æ•¸")

    btn_filter = gr.Button("é–‹å§‹ç¯©é¸", variant="primary")
    filter_result = gr.Markdown()
    btn_filter.click(
        ui_filter,
        inputs=[series_input,watt_lo, watt_hi, cct_lo, cct_hi, beam_lo, beam_hi, lumen_lo, lumen_hi, price_lo, price_hi, topk],
        outputs=[filter_result]
    )

if __name__ == "__main__":
    demo.launch()
